*   **One-Size-Fits-All Prompts:** Using the exact same system prompt for GPT-5 and Qwen3-Coder failed. Qwen was too liberal with the `llm_query` tool, spawning thousands of sub-calls when simple regex would suffice. They had to append a specific warning to Qwen's prompt: *"IMPORTANT: Be very careful about using `llm_query` as it incurs high runtime costs. Always batch as much information as reasonably possible..."*
*   **Small Models:** Models lacking strong built-in coding capabilities (e.g., Qwen3-8B) failed entirely as Root RLMs because they could not write valid Python loops to navigate the environment.
*   **Token Starvation in "Thinking" Models:** Using reasoning models (like "think" models) as the Root LM often led to failures because the model's internal "thinking" tokens consumed the entire output context window before it could finish writing the `llm_query` loop.
*   **Synchronous Execution:** The authors na√Øvely implemented `llm_query` as a blocking, sequential call. This resulted in extremely slow execution times. They explicitly cite asynchronous parallel mapping as a necessary system feature.
*   **Brittle Termination:** Distinguishing between the AI just "thinking" inside the REPL and providing the final answer was error-prone. Even with the `FINAL()` tag structural enforcement, models occasionally tried to output their "plan" as the final answer.