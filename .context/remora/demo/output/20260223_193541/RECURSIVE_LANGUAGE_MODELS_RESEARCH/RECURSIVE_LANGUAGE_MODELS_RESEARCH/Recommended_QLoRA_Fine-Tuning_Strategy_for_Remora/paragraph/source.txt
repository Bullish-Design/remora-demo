Since base models struggle with the specific nuances of an RLM environment (knowing *when* to code vs. *when* to query, formatting the `FINAL` tags, and preventing context starvation), we can emulate the paper's "Future Work" using low-cost QLoRA adapters.