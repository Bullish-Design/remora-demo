Since base models struggle with the specific nuances of an RLM environment (knowing *when* to code vs. *when* to query, formatting the `FINAL` tags, and preventing context starvation), we can emulate the paper's "Future Work" using low-cost QLoRA adapters.

Here is a recommended approach to training "Root Architect" and "Sub-Node" RLMs for Remora on a budget: