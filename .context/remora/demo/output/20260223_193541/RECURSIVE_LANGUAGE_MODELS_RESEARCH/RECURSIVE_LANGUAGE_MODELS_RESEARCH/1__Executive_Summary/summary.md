The "1. Executive Summary" outlines the core contribution of Recursive Language Models (RLMs) as a scalable, cost-effective solution to context rot in large language models by enabling recursive reasoning through external code execution, thereby maintaining performance on long-context tasks without increasing computational load. Its children detail the problem, the RLM approach, the core thesis, and the performance and cost benefits, collectively establishing RLMs as a powerful, task-agnostic alternative to traditional Transformer-based models.