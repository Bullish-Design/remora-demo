def discover(self) -> list[CSTNode]:
        """Walk root_dirs, parse files, run queries, return CSTNodes.

        Iterates over all configured languages, collecting files by extension,
        parsing them with the appropriate tree-sitter grammar, and extracting
        nodes using the corresponding query pack.

        Emits a discovery event with timing if an event_emitter is set.
        """
        start = time.monotonic()
        status = EventStatus.OK

        try:
            all_nodes: list[CSTNode] = []

            # Group extensions by language for efficient processing
            ext_to_language: dict[str, str] = {}
            for ext, grammar_module in self._languages.items():
                language = grammar_module.replace("tree_sitter_", "")
                ext_to_language[ext] = language

            # Check which languages have query packs
            languages_with_queries: dict[str, list[str]] = {}
            for ext, language in ext_to_language.items():
                pack_dir = self.query_dir / language / self.query_pack
                if pack_dir.is_dir():
                    if language not in languages_with_queries:
                        languages_with_queries[language] = []
                    languages_with_queries[language].append(ext)

            # Process each language
            for language, extensions in languages_with_queries.items():
                grammar_module = f"tree_sitter_{language}"
                files = self._collect_files(set(extensions))

                if not files:
                    continue

                # Load queries once per language
                loader = QueryLoader()
                try:
                    queries = loader.load_query_pack(self.query_dir, language, self.query_pack)
                except DiscoveryError as e:
                    logger.warning("Skipping language %s: %s", language, e)
                    continue

                # Parse files in parallel
                def _parse_single(file_path: Path) -> list[CSTNode]:
                    try:
                        parser = SourceParser(grammar_module)
                        extractor = MatchExtractor()
                        tree, source_bytes = parser.parse_file(file_path)
                        return extractor.extract(file_path, tree, source_bytes, queries)
                    except DiscoveryError:
                        logger.warning("Skipping %s due to parse error", file_path)
                        return []

                with concurrent.futures.ThreadPoolExecutor() as executor:
                    results_generator = executor.map(_parse_single, files)
                    for nodes in results_generator:
                        all_nodes.extend(nodes)

            # Deduplicate and sort
            seen_ids: set[str] = set()
            unique_nodes: list[CSTNode] = []
            for node in all_nodes:
                if node.node_id not in seen_ids:
                    seen_ids.add(node.node_id)
                    unique_nodes.append(node)

            unique_nodes.sort(key=lambda n: (str(n.file_path), n.start_byte, n.node_type, n.name))
            return unique_nodes

        except Exception:
            status = EventStatus.ERROR
            raise
        finally:
            if self.event_emitter is not None:
                duration_ms = int((time.monotonic() - start) * 1000)
                self.event_emitter.emit(
                    {
                        "event": EventName.DISCOVERY,
                        "phase": "discovery",
                        "status": status,
                        "duration_ms": duration_ms,
                    }
                )